{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# About"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Solving the Kaggle \"Getting started\" competition [Digit Recognizer](https://www.kaggle.com/c/digit-recognizer) around the [MNIST](http://yann.lecun.com/exdb/mnist/) dataset.\n",
    "\n",
    "This challenge is a computer vision problem. As for other time-based series data, **Convolutional Neural Networks** CNN are very-well suited to solve this kind of problems.\n",
    "\n",
    "This notebook's goal is four-fold:\n",
    "* Help me integrate and apply theorical knowledge learnt from various sources ([Andrew Ng](https://www.coursera.org/learn/machine-learning), [Carlos Guestrin & Emily Fox](https://www.coursera.org/specializations/machine-learning), [Jeremy Howard](http://course.fast.ai/)).\n",
    "* Learn to use [Keras](keras.io) and Theano/Tensorflow behind.\n",
    "* Study and apply visualization techniques ([Christopher Olah](http://colah.github.io/)).\n",
    "* Get more familiar with [Kaggle](http://colah.github.io/) and give back this notebook to the community."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Numpy is useful for linear algebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Pandas is a great data structures and data analysis tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Use matplotlib to visualize charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "[Keras](https://keras.io/) is a Deep Learning library, high-level framework on top of [Theano](http://deeplearning.net/software/theano/) and [TensorFlow](https://www.tensorflow.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's also import the [MNIST dataset](https://keras.io/datasets/#mnist-database-of-handwritten-digits) from Keras. There is no mention of tampering with the original data, and I checked on [the mnist db](http://yann.lecun.com/exdb/mnist/) that it should indeed consist of 28x28 grayscaled images, 60.000 training samples + 10.000 test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* X_train: Training set, images input\n",
    "* X_test: Test set, images input\n",
    "* y_train: Labels output for training set\n",
    "* y_test: Labels output for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's visualize some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAABcCAYAAAB+6068AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEPBJREFUeJztnXvQVWP7xz+3lFOOIREKj0OSihJvEyOUw8hhSiHFjwy/\nIiMjOZXzsRln0ptjI41EiFDIsanI7+2gJEVJ5FQOwxv3749nX8/ah/XUfp699tp7r76fmWf23muv\nvda9v89a977u676u63bee4QQQlQ+m5S6AUIIIaJBHboQQiQEdehCCJEQ1KELIURCUIcuhBAJQR26\nEEIkBHXoQgiREArq0J1z3Z1zC51zi51zQ6NqVCUjTcKRLrlIk1ykSWG4+iYWOecaAIuAY4HlwEyg\nj/d+fnTNqyykSTjSJRdpkos0KZxNC/hsR2Cx934JgHNuHNADqFV859zGkpY6w3u/kzTJ4L/5XivS\nJJyNRRdpEspq7/1OG9qpEJfLbsDXaa+Xp7Zl4Jwb4Jyb5ZybVcC5Ko1lqUdpEvBL2vMcXaSJrpUQ\npEnAsg3vUpiFnhfe+1HAKNiofk3XizTJRZqEI11ykSa1U4iFvgLYPe1189Q2ESBNAhqlPZcu1UiT\n9SNN6kghHfpMoMo519I51wjoDUyKplkVTyNpksPmulZykCYhSJP6U2+Xi/d+nXNuIDAFaACM8d7P\ni6xllc2+wAKkSTpfoWslG2kSjjSpJwX50L33k4HJEbUlScz13h9a6kaUGb9IkxykSQje+31L3YZK\nRZmiQgiREIoe5VIuHHLIIQAMHDgQgHPOOQeAJ598EoD77rsPgI8//rgErRNCiMKRhS6EEAmh3qn/\n9TpZCWJG27ZtC8C0adMA2GabbUL3++WX6hyPJk2aRHHa2fn6RishjrZr164AjB07tmbbkUceCcDC\nhQvzPUxFa3LNNdcAMGLECAA22aTaFjrqqKNq9nnnnXfqeti8NYHy1KUYeO9dvvuWUpOtt94agMaN\nGwNw4oknArDTTtUJnSNHjgTgzz//jOJ0eV0rstCFECIhJNaH3rFjRwAmTJgAwLbbbguAjUjWrl0L\nwF9//QUElnmnTp2ATF+67VMKunTpAgTtmzhxYuxt6NChAwAzZ86M/dylpn///gBceeWVAPzzzz8Z\n78c5whWlpUWLFkBwLRx++OEAtG7dOnT/Zs2aAXDJJZcUv3EpZKELIURCSIyFvuWWWwLQvn17AJ5+\n+mkg+JXM5vPPPwfgjjvuAGDcuHEAvP/++0DgMwW49dZbi9Di/DAfbVVVFRCvhW5+4pYtWwKw5557\n1rznXN5uzorGvvPmm29e4pbEw2GHHQbA2WefDQRzJQceeGDGfkOGDAHgm2++AaBz585AcN/NmDGj\n+I0tMvvvvz8AgwcPBuCss84CYIsttgCCe+Drr6trFNqo/4ADDgCgV69eADz44IMAfPbZZ0Vvsyx0\nIYRICOrQhRAiISTG5fLII48A0KdPn7z2N9eMhRxZyJm5ONq0aRNxC+uHJUB9+OGHsZ/b3FUXXHAB\nEAynIZ7hYyk55phjABg0aFDGdvveJ510EgCrVq2Kt2FF4owzzgDgnnvuAWDHHXcEArfC22+/DQQh\neXfeeWfG520/e793797FbXARsMCJ22+/HQg0sfDEbMxt261bNwAaNmwIBNeIaWiPcSALXQghEkLF\nW+iW0m9B/dmTdWZ5v/TSSwDcddddQDCZ88knnwDw008/AXD00UeHHqdU2MRkKRg9enTGa7NIkoxN\n7j322GNAYLUZZpkuW5bXAjJly6abVt/6hx5anavy6KOPAkFwwfTp0wG48cYbAXjvvfcA2GyzzQAY\nP348AMcdd1zGcWfNqtxFhE499VQAzj///PXu98UXXwBw7LHHAsGk6D777FPE1uWHLHQhhEgIFWuh\nW0r/G2+8AQQp/Zbo8eqrrwKBT93Crywc0azP77//HoBPP/0UCBJHzOKHwN8eZ+Eu8+E3bdo0tnNm\nk22dmtZJpl+/fgDsuuuuGdvNh2zF3CodC0vMHoXZ/9j8x2vWrMl437ZnW+bLly8H4Iknnoi+sTHR\ns2fP0O1Lly4FgsQ6Sywyy9ywcMVSIgtdCCESQsVZ6PvuW137/oorrgACK3L16tUArFy5EggshV9/\n/RWAV155JeNxQ1jyAMDll18OBIkFcXDCCSfktCMubFRgCUXGihXJXd7RIhHOO+88IBip/fzzzwDc\ndNNNpWlYxJhPfNiwYUAworXkFxvBZlvmxtVXXx263dLbbcRbiVg014ABAwB4/fXXAVi8eDEA3333\n3Xo/X8rRtCELXQghEkJFWOg2sw5BlIpZsJZua/HaNssepWW7xx57RHasfNlvv/0yXs+bF9/Siqax\nWRyLFi0CAq2ThBVcsiJu2djCJ2+99VZcTYqc6667rua5WeZWcG7KlClA4Bf+448/Mj5rJQ/MZ273\ngkWB2cjlxRdfLErb48Qi34YPH16vz1uxrlIiC10IIRJCRVjo7dq1q3lulrnRo0cPoF6LC1QUxShd\na5FB3bt3B4LIh+wIBvO7mj85Sdh3z84Mnjp1KhBkTlYi2223HQAXX3xxzTbzmZtlfsopp4R+1mKq\nbVETy/cwnnvuOSAobrcxYPMEW221Vej7Bx10UMbrDz74AIg3y1sWuhBCJISKsNBtKScIfHdmkUdt\nmVtmZvZCBqVmhx122OA+Bx98MBBoZPVImjdvDkCjRo2AIFrHvqv5Ta3kqS2ZZdmEs2fPLvwLlBlm\nmd52220Z2y0j0uLRbWnCSsT+32G1RMza3HnnnQE499xzATj55JOBYNEGq3Vklr09Wl2f3377rSht\nLyWWLduqVSsArr/+eiDXO1BbX2G+eNP077//Ll5js5CFLoQQCaGsLXSraGdZoRBYCJMmTSrKOe3X\nNn1psTlz5hTlXOvDrGZrx8MPPwwEUQphmB/YLPR169YB8PvvvwMwf/58AMaMGQMEEUE2yrHKgZb1\nZ5FCSaqsuKGoliVLlgDJqKJokSzpseFWDfHLL78Eal9Cz6xMi0e3ypuW72G1kZKAVUm0uTq7Nuw7\n271omphP3OZfzKI3bGR72mmnAcE8TBxLWcpCF0KIhFDWFrpZiOYLhCBb69lnn43kHBbjnh17Om3a\ntJrnV111VSTnqgsWmWBV/Y444ogNfuarr74C4IUXXgBgwYIFAHz00Ud5ndMy5MyKM2s1SdS22LOR\n7VOvZCwqKT2S5eWXXwaCORmrHGhx5I8//jgAP/74IxAszWjWqr2udNL7FLO0n3/++Yx9RowYAQR9\ngS1PadrZ9uxFou3+saUrs+9LCOapokYWuhBCJISyttDDsF82q9lSX8wyt9oVVhvG/Md33313zb5W\nD6YU2OopcdC1a9eM17X5mSsRm4fJjrE3zEJduHBhbG2Ki/QFm8163BBdunQBgiqlNqKp9FGb+cvN\n+obg3jesUqtlCdtIx7SbPHkyEMSdm2/cYvLNYrccGYvlf/PNN2vOYfe1rcNgFDpfJwtdCCESQsVZ\n6IVGt5ilZr/KVt/ZLLTTTz+9oOMniYkTJ5a6CZFhlfO23377jO02v9C/f/+4m1TW2PxVdtRXpfrQ\nGzRoAARZz0OGDKl5z2Lphw4dCgTf0SxzW9Xp/vvvB4JoGFvB66KLLgKCej+WgW3zXpb3YTH+kLu2\ngNVWz65wWldkoQshRELYoIXunNsdeBJoCnhglPf+HufcDsCzQAtgKdDLe/9TbcepDxZPnb6+p83Y\nX3rppXU61mWXXQbAtddeCwR11M2/ZdUaI6K1c+4NiqBJBVNSTZo0aQLkRrdYHfASzZNUOec+p0j3\nTyFYrZdSUAxNLILLLHPLzQC48MILgWAU16lTJyDI9Dz++OOBYNRyww03AMG6s9krF1ns/muvvZbx\naKunAZx55pkZn7H+qVDysdDXAZd771sBnYD/dc61AoYCU733VcDU1GtRzVykSTbSJJe1un9ykSb1\nZ4MWuvd+JbAy9Xytc24BsBvQAzgqtdsTwNvAlVE2Lrt+BMAuu+wCwL333gsEWY8//PADEPy69u3b\nFwjqm1g9E4sJNQvELLQiUBRN4sBGRLY6VL5x7HkQuyZmRVndjWysIl6J+CH1WHbXSrdu3UrdhEg1\nSa8JD4FPHYL5NMtFsUqT2dj7Fl9e1xotzzzzTOjzKKnTpKhzrgXQDpgBNE119gDfUu2SCfvMAGBA\n/ZtYsUiTXKRJJv9NPUqXXKRJPci7Q3fONQYmAIO992vS/dree++cCy0K4b0fBYxKHSO8cEQdsF9W\ny6S0qBTzW1VVVYV+ziwxm4nO/sWOmjg1iRobEdVm1RZw3Ng0sWgmqzhpvnOLGX7ggQeA8qjZUo7X\nyl577RXXqUKJWpNvv/0WCGLJ01dBs1G8YXHm06dPB4IMz6VLlwLxVk+sK3ndsc65hlR35mO995Yf\nu8o51yz1fjNg/SuobmRIk1ykSQ4NQbqEIU3qxwY7dFdtiv8bWOC9H5n21iSgX+p5P6DyFxWMFmmS\nizTJpEnqUbrkIk3qQT4ul38BfYH/OOcsL3UYcBsw3jn3P8AyoFfUjbMylenLr3Xo0CFjH5sktQWN\nDZsktSSBuoY5Fkhr4GeKoEmc2KK3VrCpQGLVxJZfs+vDWLFiBZCZWFJCtkmF6BXl/imEd999FyjN\ngi/F0MRKGVjYc/v27Wves4J/FmBh6fhxlLuNmnyiXN4DXC1vd61l+8bOXO/9MaVuRJkhTXJZ5L0/\ntNSNKDdSYYuiHpR16r8VyrJC8RAkAVhRrWysmPxDDz0EwOLFi4vZxESSPuEtNk7mzp0LBOntNkm6\n9957A5mLZlQCa9euBeCpp57KeEwaSv0XQoiEUNYWupFeKteC+7MXpBCFY2VDe/bsWeKWFI4tm2fh\nqp07dy5lcyqWW265BYDRo0cDcPPNNwMwaNAgIFjWUJQHstCFECIhuNoWiS3KycowiaZIzM53skua\n5CJNwimFLlYKdvz48UCQqGXLtVkBKytBGwXe+7wncXStZCILXQghEoIs9OIgazQXaZJL2Vvohlnq\n5kO3RR3atGkDROtLl4Ueiix0IYTYmJCFXhxkjeYiTXKpGAs9TmShhyILXQghNibijkNfDfyWekwK\nO5L7ffasw+elSS6rqa7lEXacSqVQTSB514o0CafeusTqcgFwzs1KUv2KKL6PNCnuccoBaZKLNAmn\nkO8jl4sQQiQEdehCCJEQStGhjyrBOYtJFN9HmhT3OOWANMlFmoRT7+8Tuw9dCCFEcZDLRQghEkJs\nHbpzrrtzbqFzbrFzbmhc540K59zuzrm3nHPznXPznHOXprYPd86tcM7NSf2dUMfjVqwu0iQXaRJO\nMXSRJiF474v+BzQAvgD2AhoBnwKt4jh3hN+hGdA+9XxrYBHQChgODNkYdZEm0qRUukiT8L+4LPSO\nwGLv/RLv/V/AOKBHTOeOBO/9Su/9x6nna4EFwG4FHraidZEmuUiTcIqgizQJIa4OfTfg67TXyyn8\nIi8ZzrkWQDtgRmrTIOfc/znnxjjntq/DoRKjizTJRZqEE5Eu0iQETYrWEedcY2ACMNh7vwZ4iOph\nX1tgJXB3CZtXEqRJLtIkHOmSS5SaxNWhrwB2T3vdPLWtonDONaRa+LHe++cBvPervPd/e+//AR6l\neiiYLxWvizTJRZqEE7Eu0iSEuDr0mUCVc66lc64R0BuYFNO5I8E554B/Awu89yPTtjdL2+1UYG4d\nDlvRukiTXKRJOEXQRZqEEEu1Re/9OufcQGAK1bPTY7z38+I4d4T8C+gL/Mc5Nye1bRjQxznXFvDA\nUuDCfA+YAF2kSS7SJJxIdZEm4ShTVAghEoImRYUQIiGoQxdCiISgDl0IIRKCOnQhhEgI6tCFECIh\nqEMXQoiEoA5dCCESgjp0IYRICP8PYZeYKx2c2+UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f19300ed048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    plt.subplot(150 + i)\n",
    "    plt.imshow(X_train[i], cmap=plt.get_cmap('gray'))\n",
    "plt.rcParams[\"figure.figsize\"] = [28,28]\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "and their corresponding value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4, 1, 9, 2], dtype=uint8)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 1-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's represent our labels as 1-hot encoded vectors (create one feature for every possible output):\n",
    "\n",
    "    1 → [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    \n",
    "**Note on Embeddings:** If we had categorical input, 1-hot encoding would allow us to easily multiply labels by coefficients. But this would be too slow. Keras has an **Embedding layer**, which takes an int as input, looks up a vector (instead of a huge matrix) and grabs the corresponding column as output. I won't use embeddings here since labels are an output and not an input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Verify that the new outputs match our five images above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "4 : [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      "1 : [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "9 : [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      "2 : [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "for idx in range(1,6):\n",
    "    print(y_train[idx].argmax(), ':', y_train[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Working with 60000 images right off the bat might be overkill, especially on a laptop without GPU. The idea is to experiment with a small dataset, find a good-looking model, then go on AWS rent a p2.xlarge instance and run the model on the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘data’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "mkdir data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's work on a 1000-images sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "idx = np.random.randint(60000, size=1000)\n",
    "X_sample = X_train[idx,:]\n",
    "y_sample = y_train[idx,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "split data into training and validation sets  (80/20 ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "idx = np.random.permutation(1000)\n",
    "id_train, id_val = idx[:800], idx[800:]\n",
    "Xs_train, Xs_val = X_sample[id_train,:], X_sample[id_val,:]\n",
    "ys_train, ys_val = y_sample[id_train,:], y_sample[id_val,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Save sample so we can skip all previous parts and simply load the sample data from a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "save_array('data/train_input_sample.bc', Xs_train)\n",
    "save_array('data/valid_input_sample.bc', Xs_val)\n",
    "save_array('data/train_output_sample.bc', ys_train)\n",
    "save_array('data/valid_output_sample.bc', ys_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**FLAG: Restart from here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import bcolz\n",
    "def save_array(fname, arr): c=bcolz.carray(arr, rootdir=fname, mode='w'); c.flush()\n",
    "def load_array(fname): return bcolz.open(fname)[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Loading and resizing the images every time we want to use them isn't necessary - instead we should save the processed arrays. By far the fastest way to save and load numpy arrays is using bcolz. This also compresses the arrays, so we save disk space. Here are the functions we'll use to save and load using bcolz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Xs_train = load_array('data/train_input_sample.bc')\n",
    "ys_train = load_array('data/train_output_sample.bc')\n",
    "Xs_val = load_array('data/valid_input_sample.bc')\n",
    "ys_val = load_array('data/valid_output_sample.bc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Verify that we didn't mess up the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABkAAAAEwCAYAAADvib3oAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3X2wnWV5L+D7kZ1iWkBgECYCkmKNjtWKNIMo8bAzWqA6\nlQ+FwRHGMyJf9aBWoCBW994KlEEQHLUOMITwoWVaUUutSIDujYepVAlqENRDaEFAhOEjhc5YKuQ5\nf2THRk3yPtnr413vk+uaYbKz8uN57+zF+pHFzVor5ZwDAAAAAACgJi9oewAAAAAAAIB+swABAAAA\nAACqYwECAAAAAABUxwIEAAAAAACojgUIAAAAAABQHQsQAAAAAACgOhYgAAAAAABAdSxAAAAAAACA\n6liAAAAAAAAA1Rkb5sVSSnmY1wO6L+ec2p6h33QhMAeP55xf3PYQ/aQLgTmorgsj9CGw5TxPBijv\nQq8AAQAYfQ+0PQDACNCFAABskZ4WICmlQ1JKP0kprU4pndmvoQC6RBcCrKMPAXQhQIQuBEbHnBcg\nKaVtIuLzEfGnEfGqiHhXSulV/RoMoAt0IcA6+hBAFwJE6EJgtPTyCpD9ImJ1zvnfcs7/HRHXRsSh\n/RkLoDN0IcA6+hBAFwJE6EJghPSyANk9Ih7c4OcPzd72a1JKJ6SU7kgp3dHDtQBGlS4EWKexD3Uh\nsBXwZ0MAXQiMkLFBXyDnfGlEXBoRkVLKg74ewCjShQC6EGA9fQigC4Hh6OUVIA9HxJ4b/HyP2dsA\ntia6EGAdfQigCwEidCEwQnpZgHw3Il6eUvr9lNLvRMTREXF9f8YC6AxdCLCOPgTQhQARuhAYIXN+\nC6yc83Mppf8TETdGxDYRsSznfHffJgPoAF0IsI4+BNCFABG6EBgtKefhvcWe9/MDtlTOObU9Q7/p\nQmAOVuacF7c9RD/pQmAOquvCCH0IbDnPkwHKu7CXt8ACAAAAAAAYSRYgAAAAAABAdSxAAAAAAACA\n6liAAAAAAAAA1bEAAQAAAAAAqmMBAgAAAAAAVMcCBAAAAAAAqI4FCAAAAAAAUB0LEAAAAAAAoDoW\nIAAAAAAAQHUsQAAAAAAAgOpYgAAAAAAAANWxAAEAAAAAAKpjAQIAAAAAAFTHAgQAAAAAAKiOBQgA\nAAAAAFAdCxAAAAAAAKA6FiAAAAAAAEB1xtoeAPpt0aJFRblTTz21KJdzbsycdNJJRWcBAAAAADAc\nXgECAAAAAABUxwIEAAAAAACojgUIAAAAAABQHQsQAAAAAACgOhYgAAAAAABAdSxAAAAAAACA6liA\nAAAAAAAA1bEAAQAAAAAAqmMBAgAAAAAAVGes7QFgS2y//faNmcsuu6zorCVLlvQ6zq/suOOORbmj\njz66b9eEGuywww5FuXvvvbcot+uuuzZmcs5FZ61ataood9dddxXl+unxxx9vzKxYsaLorG9/+9tF\nuTVr1hTlAAAAAEaFV4AAAAAAAADVsQABAAAAAACqYwECAAAAAABUxwIEAAAAAACojgUIAAAAAABQ\nHQsQAAAAAACgOhYgAAAAAABAdSxAAAAAAACA6oy1PQBsibPPPrsxs2TJkqKzvvvd7xblHnzwwcbM\nLbfcUnQW8Ouefvrpotzxxx9flNt///0bM+Pj40VnlXrFK17RmNlrr72Kznrxi19clMs5N2Y+8IEP\nFJ1Veh/cdNNNjZk///M/Lzrr8ccfL8oBAAAA9MIrQAAAAAAAgOr09AqQlNL9EfFMRDwfEc/lnBf3\nYyiArtGHALoQIEIXAkToQmB09OMtsJbmnL2XBYA+BIjQhQARuhAgQhcCI8BbYAEAAAAAANXpdQGS\nI+LmlNLKlNIJGwuklE5IKd2RUrqjx2sBjLLN9qEuBLYSuhDA82SACF0IjIhe3wJrSc754ZTSrhFx\nU0rpxznnb20YyDlfGhGXRkSklHKP1wMYVZvtQ10IbCV0IYDnyQARuhAYET29AiTn/PDsj49FxFcj\nYr9+DAXQNfoQQBcCROhCgAhdCIyOOS9AUkq/l1Lafv3XEXFQRPywX4MBdIU+BNCFABG6ECBCFwKj\npZe3wNotIr6aUlp/zpdyzt/sy1QA3aIPAXQhQIQuBIjQhcAISTkP7y32vJ8fvbryyisbM8ccc0zR\nWRdccEFR7owzzijKMRg559T2DP2mC+uyzTbbNGZ22WWXorO23377Xsf5lb322qsot2LFir5d8/DD\nDy/KXX/99X275lZkZc55cdtD9JMurMu2227bmPnwhz88hEl+3YIFC4pyH/jABwY8CX1SXRdG6MO2\nTU5OFuUmJiYGO0gPpqamGjMzMzNFZ5XmSoyPjxflpqenGzOlcy1durQo13WeJwOUd2FPnwECAAAA\nAAAwiixAAAAAAACA6liAAAAAAAAA1bEAAQAAAAAAqmMBAgAAAAAAVMcCBAAAAAAAqI4FCAAAAAAA\nUB0LEAAAAAAAoDop5zy8i6U0vItRpbVr1/btrH322acot2rVqr5dky2Xc05tz9BvupBevfSlL23M\nXHPNNUVnveENbyjKrVmzpjHz4he/uOgs5mRlznlx20P0ky7shsMPP7wod8UVVzRmtttuu6KzUir7\nV3/J85hf/vKXRWfdeeedRbkjjjiiMfPoo48WncWcVNeFEfpwQ+Pj40W5iYmJvp7H/1i6dGlRbmZm\npjEzPT1ddFbJ/VRyvYjy+bvO8+Tu2mOPPRoz73znO4vOuuqqq3odpyrHHHNMY+YlL3lJX685b968\nxsyHP/zhorNK/mz705/+tOist73tbUW5H//4x42Z559/vuisNpR2oVeAAAAAAAAA1bEAAQAAAAAA\nqmMBAgAAAAAAVMcCBAAAAAAAqI4FCAAAAAAAUB0LEAAAAAAAoDoWIAAAAAAAQHUsQAAAAAAAgOpY\ngAAAAAAAANUZa3sA2BJPPfVUY2bHHXcsOmvfffctyq1ataooB9Crv/zLvyzKnXTSSY2Zvfbaq+is\nlStXFuX222+/ohzQDUcddVRR7vLLLy/KzZ8/v5dxBmbevHlFude//vVFuUMPPbQxc+mllxadBczd\n+Ph42yNs0tTUVNsjbNSBBx5YlJueni7KDfv3eeuttw71ejAoH//4xxszxx13XNFZF154Ya/jMARr\n167t21l77rlnUa70v2UuWrSoMXPfffcVnTXKvAIEAAAAAACojgUIAAAAAABQHQsQAAAAAACgOhYg\nAAAAAABAdSxAAAAAAACA6liAAAAAAAAA1bEAAQAAAAAAqmMBAgAAAAAAVMcCBAAAAAAAqM5Y2wPA\nlvj617/emDnmmGOKztp3332LcsuXLy/KAVungw8+uDHzV3/1V0VnLVmypCj31FNPNWY+/vGPF511\nzjnnFOWA7thpp50aMx/60IeKzpo/f36v4wxMyZ8L77rrrqKzPvKRjxTlLrjggsbMqlWris66/fbb\ni3JQi/Hx8cbM9PT04Af5DVNTU0W5ycnJwQ4yIvp5H5Tc57C1eeSRR9oeAX5lwYIFjZn77rtvCJMM\nlleAAAAAAAAA1bEAAQAAAAAAqmMBAgAAAAAAVMcCBAAAAAAAqI4FCAAAAAAAUB0LEAAAAAAAoDoW\nIAAAAAAAQHUsQAAAAAAAgOqMtT0AbIm99967b2cdc8wxRbm//uu/bsw88sgjvY4DjJhXvvKVRblL\nLrmkMbPnnnsWnXXrrbcW5U477bTGzB133FF0FtAdO++8c1Fu2bJljZn99tuv13G22H333VeUe/e7\n312U+973vteY+djHPlZ0Vqnf/d3fbcyceuqpRWcdeeSRvY4DnTIxMTH0ay5durQxMzMzM/hBOqTk\nexYRMTk5OdhBWr4eDErJ88fjjz++6Kzddtut13HYyi1ZsqQxc9tttw1hksHyChAAAAAAAKA6jQuQ\nlNKylNJjKaUfbnDbzimlm1JK987+uNNgxwRonz4E0IUAEboQIEIXAt1Q8gqQ5RFxyG/cdmZE3JJz\nfnlE3DL7c4DaLQ99CLA8dCHA8tCFAMtDFwIjrnEBknP+VkQ8+Rs3HxoRV85+fWVEHNbnuQBGjj4E\n0IUAEboQIEIXAt0w1w9B3y3nvP5Tn38eEZv81J2U0gkRccIcrwMw6or6UBcCldOFAJ4nA0ToQmDE\nzHUB8is555xSypv59Usj4tKIiM3lALpuc32oC4GthS4E8DwZIEIXAqOh5DNANubRlNKCiIjZHx/r\n30gAnaIPAXQhQIQuBIjQhcCImesC5PqIeM/s1++JiH/ozzgAnaMPAXQhQIQuBIjQhcCIaVyApJT+\nNiK+HRGvSCk9lFI6LiLOi4g/SSndGxFvmf05QNX0IYAuBIjQhQARuhDohpTz8N5iz/v5bX1e+cpX\nFuUuu+yyotwBBxzQyzhzcvLJJzdmLrnkkiFMsnXKOae2Z+g3XdgNhx9+eFHuy1/+ct+uueOOOxbl\nnnnmmb5dk85YmXNe3PYQ/aQLt9yb3/zmotyNN9444El+2/PPP9+YOf7444vOuuqqq4pyf/zHf9yY\n+ad/+qeis3bZZZeiXInvfOc7Rbk3vvGNfbvmVqS6Lozofh9OT08X5cbHx/t2zaVLlxblZmZm+nbN\nrUXp/VR6v5couT/dl7/O8+S67b///kW5r371q0W5XXfdtZdxqNiiRYsaM/fdd98QJpmb0i6c61tg\nAQAAAAAAjCwLEAAAAAAAoDoWIAAAAAAAQHUsQAAAAAAAgOpYgAAAAAAAANWxAAEAAAAAAKpjAQIA\nAAAAAFTHAgQAAAAAAKiOBQgAAAAAAFCdsbYHoLvmz5/fmLn22muLznrNa15TlPvpT3/amHnyySeL\nzrrzzjuLcldccUVRDqjLDTfcUJT7yle+0pg54ogjis5673vfW5T7zGc+U5QDGJb777+/MfPNb36z\n6KyTTjqpKHfxxRc3ZsbGPN2BQRsfH+/bWTMzM33NseWmp6f7dpb7E+bm9ttvL8q99rWvLcptu+22\nvYxTlVtuuaUo97KXvWzAk8zNww8/XJT71Kc+VZR74IEHehmnM7wCBAAAAAAAqI4FCAAAAAAAUB0L\nEAAAAAAAoDoWIAAAAAAAQHUsQAAAAAAAgOpYgAAAAAAAANWxAAEAAAAAAKpjAQIAAAAAAFRnrO0B\n6K6jjz66MfOa17ym6Kzzzz+/b7mnnnqq6CyAzfmv//qvotxHP/rRxsz+++9fdNZZZ51VlPv3f//3\nxsz1119fdBbQHQcddFDbI2zSE0880ZhZsWJF0Vmlf37MORfl+unZZ59tzHzpS18awiRQp6mpqbZH\noI/cnzBYjz32WNsjDMULXlD2/+9/8pOfbMzsvffevY4zMCV/tl22bFnRWZ/97Gd7HacqXgECAAAA\nAABUxwIEAAAAAACojgUIAAAAAABQHQsQAAAAAACgOhYgAAAAAABAdSxAAAAAAACA6liAAAAAAAAA\n1bEAAQAAAAAAqmMBAgAAAAAAVCflnId3sZSGdzEG7mc/+1ljZrfddis665BDDinK3XTTTUU56pFz\nTm3P0G+6cOuzcOHCotz5559flHvnO9/ZmPniF79YdNYpp5xSlFuzZk1RjoFZmXNe3PYQ/aQLt9yb\n3/zmotyNN9444EkGK6Wyf/UP83nMet/4xjcaM29/+9uHMMlWq7oujOh+H7bxWJyamhr6NbvuwAMP\nLMqNj48X5WZmZhozS5cuLTqLLed5MjV40YteVJQ77bTTinJnnXVWL+O07tOf/nRj5vTTTx/CJN1R\n2oVeAQIAAAAAAFTHAgQAAAAAAKiOBQgAAAAAAFAdCxAAAAAAAKA6FiAAAAAAAEB1LEAAAAAAAIDq\nWIAAAAAAAADVsQABAAAAAACqYwECAAAAAABUZ6ztAeiuf/mXf2nMHHHEEUVnLViwoNdxAEbW/fff\nX5R797vfXZT73ve+15g5+eSTi876yU9+UpQ777zzGjMXXXRR0VkAXfWJT3yi7RFg5ExNTRXlJiYm\n+nbNfp7F3IyPjzdmcs5FZ5X8MzQ5OVl0FjAaxsaa/5Pz8uXLi856+9vf3uM0g7N27drGzOc+97mi\nsz7/+c/3Og6b0PgKkJTSspTSYymlH25w22RK6eGU0vdn/3rrYMcEaJ8+BNCFABG6ECBCFwLdUPIW\nWMsj4pCN3H5Rznmf2b++0d+xAEbS8tCHAMtDFwIsD10IsDx0ITDiGhcgOedvRcSTQ5gFYKTpQwBd\nCBChCwEidCHQDb18CPopKaVVsy9326lvEwF0jz4E0IUAEboQIEIXAiNkrguQL0TE3hGxT0Q8EhEX\nbiqYUjohpXRHSumOOV4LYJQV9aEuBCqnCwE8TwaI0IXAiJnTAiTn/GjO+fmc89qIuCwi9ttM9tKc\n8+Kc8+K5Dgkwqkr7UBcCNdOFAJ4nA0ToQmD0zGkBklJasMFPD4+IH/ZnHIBu0YcAuhAgQhcCROhC\nYPSMNQVSSn8bEeMRsUtK6aGImIiI8ZTSPhGRI+L+iDhxgDMCjAR9CKALASJ0IUCELgS6IeWch3ex\nlIZ3MQbusMMOa8xcffXVRWe94AVlL0a64YYbGjN/8Rd/UXTWgw8+WJSjXTnn1PYM/aYLGYa99tqr\nKHfeeecV5Y466qjGTGnnn3zyyY2ZX/ziF0VnbUVW1vbWALpwcI477rjGzOmnn1501stf/vKi3IoV\nKxozO+ywQ9FZb3zjG4tya9euLcqV+NrXvlaUe8c73tG3azIn1XVhxNbTh+Pj433J1ODAAw8sym0t\n348SMzMzRbmlS5cOdpAR4XkybZk3b15R7utf/3pj5i1veUuv47Tu3HPPbcx87GMfG8IkW6fSLpzr\nh6ADAAAAAACMLAsQAAAAAACgOhYgAAAAAABAdSxAAAAAAACA6liAAAAAAAAA1bEAAQAAAAAAqmMB\nAgAAAAAAVMcCBAAAAAAAqI4FCAAAAAAAUJ2Ucx7exVIa3sUYCX/0R39UlLviiiuKcq973esaM8uW\nLSs6633ve19RjnblnFPbM/SbLmSUjI2NFeU++9nPNmZOPPHEorNuvPHGxsy73vWuorPWrFlTlKvA\nypzz4raH6Cdd2K758+cX5Uo74tlnn23MTExMFJ115plnFuX6+Txm3333LcqtWrWqb9dkTqrrwgh9\nyKYN87/XrDc1NdW3s2ZmZopy09PTfbtm6fyTk5N9u2YbPE+m3xYuXFiUW758eVHuTW9609yHGQHn\nnHNOUa6kS9auXdvjNGxKaRd6BQgAAAAAAFAdCxAAAAAAAKA6FiAAAAAAAEB1LEAAAAAAAIDqWIAA\nAAAAAADVsQABAAAAAACqYwECAAAAAABUxwIEAAAAAACojgUIAAAAAABQnbG2B6Buq1atKsodeeSR\nRbnVq1c3Zvbdd9+iswCIeO6554py3/nOdxozJ554YtFZBx10UGNml112KTprzZo1RTng1/3iF7/o\n63nz5s1rzLz61a/u6zVLfPnLXy7K3XPPPQOeBOB/TE9PD/2aS5cuLcrNzMwMdpCNKJmt9Hs2MTFR\nlJucnCzKwdbijDPOKMq96U1vGvAkg3X22WcX5T75yU8W5dauXdvLOAyJV4AAAAAAAADVsQABAAAA\nAACqYwECAAAAAABUxwIEAAAAAACojgUIAAAAAABQHQsQAAAAAACgOhYgAAAAAABAdSxAAAAAAACA\n6oy1PQB1W7p0aVHummuuKcqllBozP//5z4vOAtq33XbbFeVe9rKXFeV+8IMf9DLOVunP/uzPinKX\nX355Y6akoyMiPv/5zzdmVq9eXXQWMFjz588vyv3N3/xNY+Ztb3tbr+NssZUrVxblnnvuuQFPAmwt\nJicnGzPj4+N9vebU1FRjZmZmpq/X7KdRng1qcM455zRm3ve+9w1hkrn52c9+VpQ799xzGzOXXXZZ\n0Vn+bFgXrwABAAAAAACqYwECAAAAAABUxwIEAAAAAACojgUIAAAAAABQHQsQAAAAAACgOhYgAAAA\nAABAdSxAAAAAAACA6liAAAAAAAAA1bEAAQAAAAAAqjPW9gA1uvbaaxszixYtKjrr5ptv7nWcLZZS\nKsq94x3vaMzsvvvuRWeNjZX9o/j00083Zs4999yis4DBeuELX9iYWbFiRdFZV199dVHuBz/4QVGu\n67bbbrvGzPHHH1901ic+8YmiXM65MXP66acXnXXRRRcV5YD27bzzzkW5Y489dsCT/LaHHnqoMbNs\n2bIhTAIAMHx/+Id/WJR773vf25h5wQuG///IP/vss0W50j/PfeELX+hlHCrW+E93SmnPlNJ0Sume\nlNLdKaUPzt6+c0rpppTSvbM/7jT4cQHaoQsBdCHAevoQQBcC3VCy3nsuIk7NOb8qIvaPiPenlF4V\nEWdGxC0555dHxC2zPweolS4E0IUA6+lDAF0IdEDjAiTn/EjO+c7Zr5+JiB9FxO4RcWhEXDkbuzIi\nDhvUkABt04UAuhBgPX0IoAuBbtiiN3hLKS2MiNdFxL9GxG4550dmf+nnEbFbXycDGFG6EEAXAqyn\nDwF0ITC6ij8EPaW0XURcFxEfyjk/veEHZeecc0ppo5+OmlI6ISJO6HVQgFGgCwF0IcB6+hBAFwKj\nregVICmlebGuyL6Yc/7K7M2PppQWzP76goh4bGN/b8750pzz4pzz4n4MDNAWXQigCwHW04cAuhAY\nfY0LkLRubXt5RPwo5/zpDX7p+oh4z+zX74mIf+j/eACjQRcC6EKA9fQhgC4EuqHkLbAOiIhjI+Ku\nlNL3Z287KyLOi4i/SykdFxEPRMRRgxkRYCToQgBdCLCePgTQhUAHNC5Acs63RUTaxC+/ub/j1OGF\nL3xhY2afffYpOuu1r31tr+NssQ3fq3Fzct7oWzjOycqVK4tyH/nIRxozt912W6/jwG/RhVtujz32\naMy8/vWvLzrroosu6nWcVu2www5Fufe///1FuZNOOqkxU/L9j4hYs2ZNUe6aa65pzFx44YVFZ9Fd\nunDrU9olbTj00EMbM0888cQQJmFrpA8ZJZOTk22P0JN+/reFmZmZvp1FM104GAsXLizKffOb3yzK\n7brrrj1MMzdr165tzBx77LFFZ1133XW9jsNWrugzQAAAAAAAALrEAgQAAAAAAKiOBQgAAAAAAFAd\nCxAAAAAAAKA6FiAAAAAAAEB1LEAAAAAAAIDqWIAAAAAAAADVsQABAAAAAACqYwECAAAAAABUZ6zt\nAWp08sknN2ZuuOGGorPOOeecotxOO+1UlOunv//7v2/MXHfddUVn/fM//3NR7oknnijKAe37j//4\nj8bMo48+WnTW5z73uaLcggULGjM556KzSi1atKgxc/DBBxed9Qd/8AdFuV/+8peNmX/8x38sOuuD\nH/xgUe6BBx4oygHdsO222xblzjjjjAFP8ttK/7y3evXqAU8C0A2Tk5N9yfTb9PT00K85NTU19GtC\nv+26665FuZe85CUDnuS3lT6fPu+88xozpf/NEHrlFSAAAAAAAEB1LEAAAAAAAIDqWIAAAAAAAADV\nsQABAAAAAACqYwECAAAAAABUxwIEAAAAAACojgUIAAAAAABQHQsQAAAAAACgOhYgAAAAAABAdVLO\neXgXS2l4FwOqkHNObc/Qb7rwf+y///5FucMOO6wod+SRRzZmFi5cWHRWGz71qU8V5b72ta81Zm6/\n/fZex2G0rMw5L257iH7She160YteVJS7/vrri3IHHHBAL+P8mrvvvrsod8EFFzRmrr766l7HYbRU\n14UR+rA24+PjjZnp6em+XnNmZqYxc+utt/btrIiIiYmJxkzJ96L0mlNTU307qwaeJ9ftlFNOKcpd\nfPHFA57kt61evboo94pXvGLAk0B5F3oFCAAAAAAAUB0LEAAAAAAAoDoWIAAAAAAAQHUsQAAAAAAA\ngOpYgAAAAAAAANWxAAEAAAAAAKpjAQIAAAAAAFTHAgQAAAAAAKhOyjkP72IpDe9iQBVyzqntGfpN\nFwJzsDLnvLjtIfpJF3bDJZdcUpQ77rjj+nbNlMr+1X/wwQc3Zm6++eZex2G0VNeFEfpwazQ+Pl6U\nm56eHuwgAzY1NVWUm5ycHOwgFfI8uW777bdfUe7b3/72gCf5bWeffXZRbmJiYsCTQHkXegUIAAAA\nAABQHQsQAAAAAACgOhYgAAAAAABAdSxAAAAAAACA6liAAAAAAAAA1bEAAQAAAAAAqmMBAgAAAAAA\nVMcCBAAAAAAAqI4FCAAAAAAAUJ2xtgcAAABG02mnnVaUe9WrXtWYecMb3lB01kc/+tGi3Le+9a2i\nHMComZmZKcpNTU0V5SYmJvp2VqmS30Pp7xMABqnxFSAppT1TStMppXtSSnenlD44e/tkSunhlNL3\nZ/966+DHBWiHLgTQhQDr6UMAXQh0Q8krQJ6LiFNzznemlLaPiJUppZtmf+2inPMFgxsPYGToQgBd\nCLCePgTQhUAHNC5Acs6PRMQjs18/k1L6UUTsPujBAEaJLgTQhQDr6UMAXQh0wxZ9CHpKaWFEvC4i\n/nX2plNSSqtSSstSSjv1eTaAkaQLAXQhwHr6EEAXAqOreAGSUtouIq6LiA/lnJ+OiC9ExN4RsU+s\n2/ZeuIm/74SU0h0ppTv6MC9Aq3QhgC4EWE8fAuhCYLQVLUBSSvNiXZF9Mef8lYiInPOjOefnc85r\nI+KyiNhvY39vzvnSnPPinPPifg0N0AZdCKALAdbThwC6EBh9jQuQlFKKiMsj4kc5509vcPuCDWKH\nR8QP+z8ewGjQhQC6EGA9fQigC4FuaPwQ9Ig4ICKOjYi7Ukrfn73trIh4V0ppn4jIEXF/RJw4kAkB\nRoMuBNCFAOvpQwBdCHRA4wIk53xbRKSN/NI3+j8OwGjShQC6EGA9fQigC4FuSDnn4V0speFdDKhC\nznljf5jqNF0IzMHK2t4bWRcCc1BdF0boQ2DLeZ5ct7GxkjfsiTj33HOLcqeeempj5s477yw666yz\nzirK3XTTTUU56EVpFxZ9CDoAAAAAAECXWIAAAAAAAADVsQABAAAAAACqYwECAAAAAABUxwIEAAAA\nAACojgUIAAAAAABQHQsQAAAAAACgOhYgAAAAAABAdVLOeXgXS2l4FwOqkHNObc/Qb7oQmIOVOefF\nbQ/RT7qTM+TWAAAGXUlEQVQQmIPqujBCHwJbzvNkgPIu9AoQAAAAAACgOhYgAAAAAABAdSxAAAAA\nAACA6liAAAAAAAAA1bEAAQAAAAAAqmMBAgAAAAAAVMcCBAAAAAAAqI4FCAAAAAAAUB0LEAAAAAAA\noDpjQ77e4xHxwG/ctsvs7V1l/naZv12Dnn+vAZ7dJl04eszfrq7PH6EP50IXjp6uzx/R/d+D+Tev\nxi6M0IejyPztMv/m6cLuMH+7zN+ukenClHMe4BwFA6R0R855catD9MD87TJ/u7o+/yjp+vfS/O0y\nf/tq+D2Mgq5/H83fvq7/HszPel3/Xpq/XeZvV9fnHyVd/16av13mb9coze8tsAAAAAAAgOpYgAAA\nAAAAANUZhQXIpW0P0CPzt8v87er6/KOk699L87fL/O2r4fcwCrr+fTR/+7r+ezA/63X9e2n+dpm/\nXV2ff5R0/Xtp/naZv10jM3/rnwECAAAAAADQb6PwChAAAAAAAIC+am0BklI6JKX0k5TS6pTSmW3N\nMVcppftTSnellL6fUrqj7XlKpJSWpZQeSyn9cIPbdk4p3ZRSunf2x53anHFzNjH/ZErp4dn74fsp\npbe2OePmpJT2TClNp5TuSSndnVL64OztnbgPNjN/Z+6DUdT1LozoXh/qwnbpQjal632oC4dLF7ZL\nFw6OLhyurndhRLf7UBeyKV3vwgh9OGxd7sIIfTjw+dp4C6yU0jYR8f8i4k8i4qGI+G5EvCvnfM/Q\nh5mjlNL9EbE45/x427OUSin9r4j4z4i4Kuf86tnbzo+IJ3PO583+S2WnnPMZbc65KZuYfzIi/jPn\nfEGbs5VIKS2IiAU55ztTSttHxMqIOCwi/nd04D7YzPxHRUfug1FTQxdGdK8PdWG7dCEbU0Mf6sLh\n0oXt0oWDoQuHr+tdGNHtPtSFbEwNXRihD4ety10YoQ8Hra1XgOwXEatzzv+Wc/7viLg2Ig5taZat\nRs75WxHx5G/cfGhEXDn79ZWx7h/OkbSJ+Tsj5/xIzvnO2a+fiYgfRcTu0ZH7YDPzM3e6sAW6sF26\nkE3Qh0OmC9ulC9kEXThkXe/CiG73oS5kE3RhC7reh13uwgh9OGhtLUB2j4gHN/j5QzFC35RCOSJu\nTimtTCmd0PYwPdgt5/zI7Nc/j4jd2hxmjk5JKa2afbnbSL4U7DellBZGxOsi4l+jg/fBb8wf0cH7\nYETU0IURdfRh5x6HG9G5x6EuZAM19KEuHA2dexzqQjagC0dD5x6Hm9Cpx6IuZAM1dGGEPhwVnXss\n6sP+8yHoc7ck57xPRPxpRLx/9qVWnZbXvR/a8N8TrTdfiIi9I2KfiHgkIi5sd5xmKaXtIuK6iPhQ\nzvnpDX+tC/fBRubv3H1A31XVh114HG5E5x6HupAK6cL2de5xqAupkC4cDZ16LOpCKqUP29e5x6I+\nHIy2FiAPR8SeG/x8j9nbOiPn/PDsj49FxFdj3Uv0uujR2fdpW/9+bY+1PM8WyTk/mnN+Pue8NiIu\nixG/H1JK82JdEXwx5/yV2Zs7cx9sbP6u3QcjpvNdGFFNH3bmcbgxXXsc6kI2ovN9qAvb17XHoS5k\nI3ThaOjM43BTuvRY1IVsROe7MEIfjoKuPRb14eC0tQD5bkS8PKX0+yml34mIoyPi+pZm2WIppd+b\n/UCXSCn9XkQcFBE/bHeqObs+It4z+/V7IuIfWpxli60vgVmHxwjfDymlFBGXR8SPcs6f3uCXOnEf\nbGr+Lt0HI6jTXRhRVR924nG4KV16HOpCNqHTfagLR0OXHoe6kE3QhaOhE4/DzenKY1EXsgmd7sII\nfTgquvRY1IeDlda9eqaFC6f01oi4OCK2iYhlOedzWhlkDlJKe8e67W1ExFhEfKkL86eU/jYixiNi\nl4h4NCImIuJrEfF3EfHSiHggIo7KOY/khwZtYv7xWPcyqhwR90fEiRu8N95ISSktiYj/GxF3RcTa\n2ZvPinXviTfy98Fm5n9XdOQ+GEVd7sKIbvahLmyXLmRTutyHunD4dGG7dOHg6MLh6noXRnS7D3Uh\nm9LlLozQh23ochdG6MOBz9fWAgQAAAAAAGBQfAg6AAAAAABQHQsQAAAAAACgOhYgAAAAAABAdSxA\nAAAAAACA6liAAAAAAAAA1bEAAQAAAAAAqmMBAgAAAAAAVMcCBAAAAAAAqM7/B+2pOZWIik1TAAAA\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1920752d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    plt.subplot(150 + i)\n",
    "    plt.imshow(Xs_train[i], cmap=plt.get_cmap('gray'))\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 : [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      "3 : [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      "9 : [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      "8 : [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      "7 : [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "for idx in range(1,6):\n",
    "    print(ys_train[idx].argmax(), ':', ys_train[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's create a mini-batch generator. This means that we'll only take a subset of all data during one iteration (epoch).\n",
    "\n",
    "\n",
    "The Keras ImageDataGenerator creates mini-batches, and will allow us later to add **data augmentation** to our model. It expects a 4-dim array, so let's add a 4th dimension to our input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if len(Xs_train.shape) < 4:\n",
    "    Xs_train = np.expand_dims(Xs_train, 4)\n",
    "    Xs_val = np.expand_dims(Xs_val, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gen = image.ImageDataGenerator()\n",
    "batches = gen.flow(Xs_train, ys_train, batch_size=50)\n",
    "test_batches = gen.flow(Xs_val, ys_val, batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# CNN VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Since the [VGG model](https://gist.github.com/baraldilorenzo/07d7802847aaad0a35d3)'s layers are almost all convolutional, let's start working with this model. VGG16 is the smallest of the VGG family, hence the fastest to train, while still giving good results.\n",
    "\n",
    "Keras has a [VGG16](https://keras.io/applications/#vgg16) model pre-trained on ImageNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Notes on VGG16:**\n",
    "* puts 50% dropout after each of its dense layers (preferred flavor of regularization).\n",
    "* isn't normalized (try [fast.ai Vgg16BN](https://github.com/fastai/courses/blob/master/deeplearning1/nbs/vgg16bn.py) later, should allow for higher learning rates)\n",
    "* designed to create layers of gradually increasing complexity, which is good for transfer learning\n",
    "* default input size is 224x224x3, and we cannot ask it to use an input shape of (28, 28, 1). We'll have to create our own version of VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.core import Flatten, Dense, Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mean_px = Xs_train.mean().astype(np.float32)\n",
    "std_px = Xs_train.std().astype(np.float32)\n",
    "def norm_input(x): return (x-mean_px)/std_px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "VGG16 = Sequential([\n",
    "    Lambda(norm_input, input_shape=(28,28,1)),\n",
    "    Conv2D(32, (3,3), activation='relu'),\n",
    "    Conv2D(32, (3,3), activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We want to define a **Learning rate approach**. They all use the same theory: if the parameter that I’m changing, the derivative of that parameter is consistently of a very low magnitude, then if the derivative of this mini-batch is higher than that, what I really care about is the relative difference between how much this variable tends to change.\n",
    "\n",
    "Let's use [**Adam**](https://keras.io/optimizers/#adam), which is RMSProp + Momentum, making training neural networks (NN) much faster.\n",
    "\n",
    "Definitions:\n",
    "* RMSProp: Divide the learning rate for a weight by a running average of the magnitudes of recent gradients for that weight\n",
    "* Momentum: Instead of using the gradient to change the position of the weight \"particle\", use it to change the velocity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We also need to specify a **Loss function**. We'll use **categorical crossentropy**\n",
    "\n",
    "Definitions:\n",
    "* Loss function: Usually a function defined on a data point (prediction and label), and measures the penalty. It's part of the cost function.\n",
    "* Cross-entropy: Measure the distance between original probability score and resulting one-hot encoding.\n",
    "\n",
    "**Note:** **Clipping** is very important for getting the best cross-entropy loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "VGG16.compile(optimizer=Adam(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "16/16 [==============================] - 2s - loss: 3.2185e-04 - acc: 1.0000 - val_loss: 0.0912 - val_acc: 0.9750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/3\n",
      "16/16 [==============================] - 2s - loss: 2.0855e-04 - acc: 1.0000 - val_loss: 0.1597 - val_acc: 0.9600\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/3\n",
      "16/16 [==============================] - 2s - loss: 1.5615e-04 - acc: 1.0000 - val_loss: 0.0843 - val_acc: 0.9750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f191010e080>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VGG16.fit_generator(batches, steps_per_epoch=800//50,\n",
    "                    validation_data=test_batches,\n",
    "                    validation_steps=200//50,\n",
    "                    epochs=3,\n",
    "                    workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "97.5% accuracy on the validation test, looking good! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "VGG16.optimizer.lr=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "16/16 [==============================] - 2s - loss: 1.1589e-04 - acc: 1.0000 - val_loss: 0.0863 - val_acc: 0.9750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/3\n",
      "16/16 [==============================] - 2s - loss: 1.1989e-04 - acc: 1.0000 - val_loss: 0.0305 - val_acc: 0.9900\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/3\n",
      "16/16 [==============================] - 2s - loss: 9.6644e-05 - acc: 1.0000 - val_loss: 0.0210 - val_acc: 0.9900\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f19103b1a58>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VGG16.fit_generator(batches, steps_per_epoch=800//50,\n",
    "                    validation_data=test_batches,\n",
    "                    validation_steps=200//50,\n",
    "                    epochs=3,\n",
    "                    workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decreasing the learning rate gives us a 99% accuracy on validation test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
